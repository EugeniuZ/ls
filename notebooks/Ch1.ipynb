{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and Scientific Research\n",
    "Various parts of statistics and the connections between them make much more sense when you understand how it is used in the context of scientific research. The goal of the scientific research is to explain _why_ something happens.\n",
    "\n",
    " 1. Research starts with some observation. The observation should be confirmed by some data you collect in addition to your initial observation.\n",
    " 2. You create a **theory** that explains what you have initially observed.\n",
    " 3. The theory is further used to **make predictions** (hypotheses) about an outcome. Predictions should be **verifiable**, i.e. we should be able to measure something in order to support or falsify a prediction.\n",
    " The predictions are expressed in terms of a **cause** and an **outcome**. The cause (predictor variable / independent variable) is the variable that the experimenter modifies. The outcome variable (dependent variable) is believed to the caused by the predictor variable.\n",
    " 4. You collect data to verify that the prediction is true. Actually you can't say that the prediction is true based on the collected data (_because you can't collect all the possible data and prove that all other hypotheses are false_). Instead you create a \"contrarian\" prediction and try to show that the probability of the data you collected is very small if contrarian prediction is true (by convention if the probability is < 0.05 we can claim that the contrarian prediction is false and thus the initial/experimental prediction is probably true). The contrarian prediction is called **null hypothesis**.\n",
    " 5. You analyse the data. Analysis is done first looking at the data graphically and by fitting a statistical model to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of variables\n",
    "\n",
    "<div class='alert alert-danger'>\n",
    "    <ul>\n",
    "        <li> Which statistical methods (e.g. summarization techniques) can be applied for which kinds of variables ?\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "> Variables themselves can be classified based on whether they can be represented by numerical quantities. \n",
    ">\n",
    ">  * **Categorical variables** - the variable represents a distinct class or entity to which the measured entity can belong. A category can be represented by a number but the number itself doesn't have an absolute value, it is just an identifier. \n",
    ">    * **Nominal variable** - The value of the variable is used only to identify the variable. No relationships between values can be made (except equality). The value, even if is a number, doesn't represent a numeric quantity.\n",
    ">    * **Binary variable** - special case of nominal variable with only 2 categories.\n",
    ">    * **Ordinal variables** - nominal variable with the additional property that categories can be arranged in a specific order, e.g. grades of various kinds. In general any subjective score reported by a human is an ordinal variable since it is a relative assessment of the thing being measured. Note that scores can be numbers on some scale or categories themselves (e.g. bad, satisfactory, good, very good).\n",
    ">  * **Numerical variables** - can be variables with exact values (discrete variables) and values taken from a an infinite continuum of values (continous variables). Put another way, if we have a finite numerical interval, a discrete variable can take a finite number of values in that interval whereas a continuous variable - infinite number of values. In the case of the continuous variables the precision of the value is determined by the precision and resolution of the measuring device. For practical purposes continuous variables are approximated to some precision so they become discrete. For numerical variables we distinguish 2 subtypes with increasing number of relationships between values:\n",
    ">     * **Interval variables** - ordinal variables with the addition that the equal differences between 2 values represent equal changes in the property of the variable. There exists a smallest difference between 2 values which we call the unit of measure (that distinguishes 2 successive values). A good example of interval variables are dates.\n",
    ">     * **Ratio variables** - interval variables with a meaningful zero value that represents the absence of the quantity being measured. Length, weight are good examples. The variables in this category have also meaningful ratios. Dates are not a ratio variable because the ratio of dates makes no sense, also we don't have an absolute date of \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of research methods\n",
    "\n",
    "Based on the role of the experimenter in the research we distinguish 2 types of research methods:\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "Add more information about the relationship between scientific research and statistics, in particular:\n",
    "    <ul>\n",
    "        <li> <em>Q: What kind of statistical techniques are applied in correlational research vs experimental ?</em>\n",
    "        <li> A: Statistical techniques are not divided by this criteria.\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "1. Correlational research - the experimenter only observes what has already happened and tries to find correlations between different variables. Correlation only means that variables tend to vary together in some way, not necessarily the change in one being the cause of the change in the other. However the end goal is to predict the value of some variables given the value of another variable. \n",
    "<div class='alert alert-danger'>\n",
    "    What does statistics say about when can we state that one variable reliably predicts the values of another one (rather than the data we collect happening purely by chance) ? How many times observations of co-occurence we need to collect ? How many values should the predictor variable have vs the outcome variable ? \n",
    "</div>\n",
    "2. Experimental research - the experimenter tries to show that changes in the predictor variable actually causes the changes in outcome variable.\n",
    "\n",
    "> **Causality** implies the following:\n",
    ">   * If the cause happens the outcome should also happen\n",
    ">   * The outcome happens _close in time after_ the cause\n",
    ">   * If the cause doesn't happen the outcome is absent too\n",
    "\n",
    "In experimental research we do an experiment where the cause is present and we observe whether the outcome is present too and another experiment where the cause is absent and we observe whether the outcome is also absent.\n",
    "Such experiments can be run in 2 ways:\n",
    "* Run each of the 2 experiments with different participants. The difficulty here is to make sure the difference in experiment outcomes comes _mainly_ from the manipulation of the cause (**systematic variation**) rather than the difference in the 2 groups of participants (**unsystematic variation**). \n",
    "<div class='alert alert-danger'>\n",
    "    <ul>\n",
    "        <li> <em>Q: How does statistics measure the change in the outcome (when cause is present vs absent)?</em>\n",
    "        <li> <em>Q: How much change is considered statistically significant ?</em>\n",
    "        <li> <em>Q: How does statistics quantify how much change is due to systematic variation vs unsystematic variation ?</em>\n",
    "    </ul>\n",
    "</div>\n",
    "* Run each of the 2 experiments with the same number of participants. The participants are again split in 2 groups though, one group does the experiments in one order and the other in another order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Analysis Constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library('ggplot2')\n",
    "library('e1071')\n",
    "options(repr.plot.width=6, repr.plot.height=3)\n",
    "options(digits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFoCAMAAABJ+DwrAAAAPFBMVEUAAAAzMzNNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- rnorm(10000)\n",
    "d <- data.frame(value=x)\n",
    "ggplot(d, aes(x=value)) + geom_histogram(binwidth=0.1, color=\"white\", fill=rgb(0.2,0.7,0.1,0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std. dev=0.9917\n",
      "Prob(x <= -3.78) = 0.0001\n",
      "Prob(x <= -2.98) = 0.0017\n",
      "Prob(x <= -1.98) = 0.0242\n",
      "Prob(x <= -0.99) = 0.1576\n",
      "Prob(x <=  0.00) = 0.5033\n",
      "Prob(x <=  0.99) = 0.8430\n",
      "Prob(x <=  1.98) = 0.9783\n",
      "Prob(x <=  2.98) = 0.9984\n",
      "Prob(x <=  4.15) = 1.0000\n",
      "Prob(-1.96 < x <=  1.96) = 95.03%\n",
      "Prob(-2.58 < x <=  2.58) = 99.11%\n",
      "Prob(-3.29 < x <=  3.29) = 99.89%\n"
     ]
    }
   ],
   "source": [
    "sd_d <- sd(x)\n",
    "cat(sprintf('Std. dev=%.4f\\n', sd_d))\n",
    "cdf <- ecdf(x)\n",
    "values <- c(min(x), -3 * sd_d, -2 * sd_d, -1 * sd_d, 0 * sd_d, 1 * sd_d, 2 * sd_d, 3 * sd_d, max(x))\n",
    "cat(sprintf('Prob(x <= %5.2f) = %.4f\\n', values, cdf(values)), sep='')\n",
    "special_z_scores <- c(1.96, 2.58, 3.29)\n",
    "cat(sprintf('Prob(%5.2f < x <= %5.2f) = %.2f%%\\n', -special_z_scores, special_z_scores, 100 * (cdf(special_z_scores) - cdf(-special_z_scores))), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of Deviation from Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skew        =-0.0064 \n",
      "kurtosis    =0.0539 \n"
     ]
    }
   ],
   "source": [
    "cat(sprintf('%-12s=%.4f', 'skew', e1071::skewness(d$value)), '\\n')  # left/right (positive/negative) tail asymmetry\n",
    "cat(sprintf('%-12s=%.4f', 'kurtosis', e1071::kurtosis(d$value)), '\\n') # center/tails deviation (negative-> flatter tails, positive -> higher distribution in the center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center of Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For symmetric distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mean=-0.0042 \n"
     ]
    }
   ],
   "source": [
    "cat(sprintf('%12s=%.4f', 'mean', mean(d$value)), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For asymmetric distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mode=3.0000 (repeated 3 times)         mode=9.0000 (repeated 3 times) \n",
      "      median=5.5000 (sorted=1 2 3 3 3 4 5 6 7 8 9 9 9 100) size=14 \n"
     ]
    }
   ],
   "source": [
    "d2 <- c(3, 3, 6, 100, 5, 9, 1, 9, 7, 8, 3, 9, 2, 4);\n",
    "ux <- unique(d2);  # get unique values in the set\n",
    "tab <- tabulate(match(d2, ux));  # match - returns the indexes in ux for each element of x, tabulate - counts the frequencies of values in an vector of integers\n",
    "mode <- ux[tab == max(tab)];  # returns elements in ux at positions where the highest frequency matches\n",
    "\n",
    "cat(sprintf('%12s=%.4f (repeated %d times)', 'mode', mode, max(tab)), '\\n')\n",
    "cat(sprintf('%12s=%.4f (sorted=%s) size=%d', 'median', median(d2), paste(sort(d2), collapse=' '), length(d2)), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode and mean make more sense for:\n",
    "* asymmetric distributions with a long tail\n",
    "* observed quantity is an ordinal variable (no meaningful difference between values, e.g. IQ scores)\n",
    "\n",
    "The mean is affected by the presence of outliers. Median and mode - not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other kinds of Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arithmetic mean doesn't apply in all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Harmonic Mean (Average of Ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arithmetic mean of velocities: 20.00 km/h \n",
      "Harmonic mean of velocities: 15.00 km/h \n"
     ]
    }
   ],
   "source": [
    "velocities <- c(30, 10) # travel downhil a distance of 30km with 30km/h, uphill with 10km/h\n",
    "cat(sprintf('Arithmetic mean of velocities: %.2f km/h \\n', mean(velocities)))  # the 'average distance' is 20 which is wrong\n",
    "cat(sprintf('Harmonic mean of velocities: %.2f km/h \\n', 1/mean(1/velocities)))  # harmonic average is the true average velocity in this case (60 km covered in 4 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic mean of P/E ratios: 93.46 \n"
     ]
    }
   ],
   "source": [
    "# weighted harmonic mean\n",
    "peratios <- c(30, 1000) # P/E ratios of some companies\n",
    "# weight of each company in an investment portfolio\n",
    "weights <- c(0.3, 0.7) \n",
    "# assume a total portofolio of $10000, means $3000 worth of shares of company with P/E 30 and $7000 of shares of company with P/E 1000\n",
    "# assume earnings is $1 -> price per share $30 and $1000 respectively\n",
    "# so 100 shares of first company + 7 shares of second company\n",
    "# a total of 107 shares -> total earnings -> $107 dollars\n",
    "# combined P/E: $10000 / $107 ~ 93.46\n",
    "peratio <- sum(weights) / sum(weights/peratios)\n",
    "cat(sprintf('Harmonic mean of P/E ratios: %.2f \\n', peratio))  # P/E ratio of the combined portfolio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geometric Mean (Average of Rate of Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Yearly Sales increase: 129.03%"
     ]
    }
   ],
   "source": [
    "# average increase in sales\n",
    "# $100 -> $110 -> $165 -> $132 -> $277.2\n",
    "# $100 -> $129.03 -> $166.49 -> $214.82 -> $277.18 (1.2903 yearly rate)\n",
    "sales_rate <- c(1.1, 1.5, 0.8, 2.1)\n",
    "avg <- prod(sales_rate)^(1/length(sales_rate))\n",
    "cat(sprintf('Average Yearly Sales increase: %.2f%%', 100 * avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value in geometric progression: 5.66 (5.66)"
     ]
    }
   ],
   "source": [
    "# middle value in a geometric progression\n",
    "# it is the antilogarithm(exponentiation) of arithmetic mean of logarithmic values of the measurements\n",
    "# bringing a geometic progression to logarithmic scale makes it linear and thus arithmetic mean applies\n",
    "s <- c(32, 16, 8, 4, 2, 1)\n",
    "avg <- prod(s)^(1/length(s))\n",
    "# better formula \n",
    "avg1 <- 2^(sum(log2(s)) / length(s)) # avoids integer overflow when computing prod(s)\n",
    "cat(sprintf('Average value in geometric progression: %.2f (%.2f)', avg, avg1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How to determine which mean to use for the distribution (arithmetic vs geometric)__ ?\n",
    "Davies Test of Logarithmic Distribution -> if the coefficient <= 0.2 -> geometric, else arithmetic. Prerequisites for using the test:\n",
    "* Distribution is clearly asymmetrical\n",
    "* The distribution is positively skewed (more samples on the left side)\n",
    "* Must have at least 50 observations (quartile are less reliable with smaller samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew: -0.107100 Davies coefficient: -0.096 (use geometric mean)\n",
      "Skew: -0.777712 Davies coefficient: -0.141 (use geometric mean) \n",
      "Skew: 0.343071 Davies coefficient: 0.104 (use geometric mean)\n",
      "Skew: 1.597691 Davies coefficient: 0.226 (use arithmetic mean) \n"
     ]
    }
   ],
   "source": [
    "davies_test <- function(sample){\n",
    "    quartiles <- quantile(sample, type=5)\n",
    "    LQ <- quartiles[2]\n",
    "    MQ <- quartiles[3]\n",
    "    UQ <- quartiles[4]\n",
    "    return((log10(LQ) + log10(UQ) - 2 * log10(MQ)) / (log10(UQ) - log10(LQ)))\n",
    "}\n",
    "\n",
    "# bad sample because is symmetric\n",
    "d1 <- rnorm(1000, mean=5, sd=1)\n",
    "cat(sprintf('Skew: %f ', e1071::skewness(d1)))\n",
    "dtv <- davies_test(d1)\n",
    "cat(sprintf('Davies coefficient: %.3f (use %s mean)\\n', dtv, ifelse(dtv < 0.2, 'geometric', 'arithmetic')))\n",
    "# bad sample because is right skewed\n",
    "d1 <- rbeta(1000,10,2)\n",
    "cat(sprintf('Skew: %f ', e1071::skewness(d1)))\n",
    "dtv <- davies_test(d1)\n",
    "cat(sprintf('Davies coefficient: %.3f (use %s mean) \\n', dtv, ifelse(dtv < 0.2, 'geometric', 'arithmetic')))\n",
    "# probably bad sample because too few samples\n",
    "d1 <- rbeta(20,2,4)\n",
    "cat(sprintf('Skew: %f ', e1071::skewness(d1)))\n",
    "dtv <- davies_test(d1)\n",
    "cat(sprintf('Davies coefficient: %.3f (use %s mean)\\n', dtv, ifelse(dtv < 0.2, 'geometric', 'arithmetic')))\n",
    "# good sample\n",
    "d1 <- rgeom(1000, 0.2)\n",
    "cat(sprintf('Skew: %f ', e1071::skewness(d1)))\n",
    "dtv <- davies_test(d1)\n",
    "cat(sprintf('Davies coefficient: %.3f (use %s mean) \\n', dtv, ifelse(dtv < 0.2, 'geometric', 'arithmetic')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispersion in a Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 <- c(22, 40, 53, 57, 93, 98, 103, 108, 116, 121, 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>22</li>\n",
       "\t<li>252</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 22\n",
       "\\item 252\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 22\n",
       "2. 252\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  22 252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>22</li>\n",
       "\t<li>252</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 22\n",
       "\\item 252\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 22\n",
       "2. 252\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  22 252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "range(d2)\n",
    "c(min(d2), max(d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>0%</dt>\n",
       "\t\t<dd>22</dd>\n",
       "\t<dt>25%</dt>\n",
       "\t\t<dd>53</dd>\n",
       "\t<dt>50%</dt>\n",
       "\t\t<dd>98</dd>\n",
       "\t<dt>75%</dt>\n",
       "\t\t<dd>116</dd>\n",
       "\t<dt>100%</dt>\n",
       "\t\t<dd>252</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[0\\textbackslash{}\\%] 22\n",
       "\\item[25\\textbackslash{}\\%] 53\n",
       "\\item[50\\textbackslash{}\\%] 98\n",
       "\\item[75\\textbackslash{}\\%] 116\n",
       "\\item[100\\textbackslash{}\\%] 252\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "0%\n",
       ":   2225%\n",
       ":   5350%\n",
       ":   9875%\n",
       ":   116100%\n",
       ":   252\n",
       "\n"
      ],
      "text/plain": [
       "  0%  25%  50%  75% 100% \n",
       "  22   53   98  116  252 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q5 <- quantile(d2, type=1) # default is type=7\n",
    "q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "63"
      ],
      "text/latex": [
       "63"
      ],
      "text/markdown": [
       "63"
      ],
      "text/plain": [
       "[1] 63"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63"
     ]
    }
   ],
   "source": [
    "IQR(d2, type=1)\n",
    "cat(q5[4]-q5[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>-1.21808</td></tr>\n",
       "\t<tr><td>-0.92432</td></tr>\n",
       "\t<tr><td>-0.71216</td></tr>\n",
       "\t<tr><td>-0.64688</td></tr>\n",
       "\t<tr><td>-0.05935</td></tr>\n",
       "\t<tr><td> 0.02225</td></tr>\n",
       "\t<tr><td> 0.10386</td></tr>\n",
       "\t<tr><td> 0.18546</td></tr>\n",
       "\t<tr><td> 0.31602</td></tr>\n",
       "\t<tr><td> 0.39762</td></tr>\n",
       "\t<tr><td> 2.53557</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t -1.21808\\\\\n",
       "\t -0.92432\\\\\n",
       "\t -0.71216\\\\\n",
       "\t -0.64688\\\\\n",
       "\t -0.05935\\\\\n",
       "\t  0.02225\\\\\n",
       "\t  0.10386\\\\\n",
       "\t  0.18546\\\\\n",
       "\t  0.31602\\\\\n",
       "\t  0.39762\\\\\n",
       "\t  2.53557\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| -1.21808 |\n",
       "| -0.92432 |\n",
       "| -0.71216 |\n",
       "| -0.64688 |\n",
       "| -0.05935 |\n",
       "|  0.02225 |\n",
       "|  0.10386 |\n",
       "|  0.18546 |\n",
       "|  0.31602 |\n",
       "|  0.39762 |\n",
       "|  2.53557 |\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]    \n",
       " [1,] -1.21808\n",
       " [2,] -0.92432\n",
       " [3,] -0.71216\n",
       " [4,] -0.64688\n",
       " [5,] -0.05935\n",
       " [6,]  0.02225\n",
       " [7,]  0.10386\n",
       " [8,]  0.18546\n",
       " [9,]  0.31602\n",
       "[10,]  0.39762\n",
       "[11,]  2.53557"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scale(d2)  # computing the z-scores for a distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the distribution, the mean and the standard deviation we could move on to compute the probabilty that a given value would occur in that distribution. Of course to do that we need to assume a certain distribution of scores first, e.g. assume that the samples follow a normal distribution. We would then use the precomputed tables for that distribution (a mapping from values to probabilities) to compute the cumulative probability of occurrence of a value of that magnitude or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming a normal distribution in the underlying population for the sample [22, 40, 53, 57, 93, 98, 103, 108, 116, 121, 252], the probability of obtaining a value of 9 or more would be 92.37%"
     ]
    }
   ],
   "source": [
    "sample_value <- 9\n",
    "# mean and stddev should have been of the population\n",
    "z <- (sample_value - mean(d2)) / sd(d2)\n",
    "cat(\n",
    "    sprintf(\n",
    "        paste(\n",
    "            'Assuming a normal distribution in the underlying population for the sample [%s],',\n",
    "            'the probability of obtaining a value of %d or more would be %.2f%%',\n",
    "            sep=' '\n",
    "        ), \n",
    "        toString(d2), \n",
    "        sample_value, \n",
    "        100 * pnorm(z, lower.tail=FALSE), '\\n'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same probability with the outlier removed: 98.04%"
     ]
    }
   ],
   "source": [
    "d2_1 <- d2[1:length(d2)-1]\n",
    "z_1 <- (sample_value - mean(d2_1)) / sd(d2_1)\n",
    "cat(\n",
    "    sprintf(\n",
    "        paste(\n",
    "            'Same probability with the outlier removed: %.2f%%',\n",
    "            sep=' '\n",
    "        ), \n",
    "        100 * pnorm(z_1, lower.tail=FALSE), '\\n'\n",
    "    )\n",
    ") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
